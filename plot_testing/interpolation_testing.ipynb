{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2331fa-6a64-4dd1-92d7-58e9444f8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from io import StringIO, BytesIO\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata, NearestNDInterpolator\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d79bc36-601d-4655-a79e-873d78a302ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_header(content):\n",
    "    \"\"\"Extract and parse the common header from a .dat file.\"\"\"\n",
    "    header_data = {}\n",
    "    for line in content.splitlines():\n",
    "        if line.startswith(\"# File:\"):\n",
    "            continue\n",
    "        if line.startswith('#'):\n",
    "            if '=' in line:\n",
    "                key, value = line[2:].strip().split('=', 1)\n",
    "                header_data[key.strip()] = value.strip()\n",
    "            else:\n",
    "                header_data.setdefault('comments', []).append(line[2:].strip())\n",
    "    return header_data\n",
    "\n",
    "\n",
    "def interpolate_data(df, grid_params, k=3, power=1.0, average_duplicates=True):\n",
    "    \"\"\"Regrid all numeric variables in df using k-NN inverse distance weighting (IDW).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Must contain 'x' and 'y' columns and any number of numeric variables to interpolate.\n",
    "    grid_params : dict\n",
    "        {\n",
    "          \"x\": {\"min\": ..., \"max\": ..., \"n\": ...},\n",
    "          \"y\": {\"min\": ..., \"max\": ..., \"n\": ...}\n",
    "        }\n",
    "    k : int\n",
    "        Number of neighbors for weighting.\n",
    "    power : float\n",
    "        IDW power parameter. Set to 0 for uniform averaging of neighbors.\n",
    "    average_duplicates : bool\n",
    "        If True, average duplicate (x,y) rows before building the tree.\n",
    "    \"\"\"\n",
    "    print(\"Applying interpolation with IDW (k={}, power={})\".format(k, power))\n",
    "    x_min, x_max, x_n = grid_params[\"x\"][\"min\"], grid_params[\"x\"][\"max\"], grid_params[\"x\"][\"n\"]\n",
    "    y_min, y_max, y_n = grid_params[\"y\"][\"min\"], grid_params[\"y\"][\"max\"], grid_params[\"y\"][\"n\"]\n",
    "    print(grid_params)\n",
    "    \n",
    "    \n",
    "    # Average duplicate (x,y) points\n",
    "    if average_duplicates:\n",
    "        # only average numeric columns; non-numerics are dropped\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if \"x\" not in numeric_cols: numeric_cols.append(\"x\")\n",
    "        if \"y\" not in numeric_cols: numeric_cols.append(\"y\")\n",
    "        dfu = (df[numeric_cols]\n",
    "               .groupby([\"x\", \"y\"], as_index=False)\n",
    "               .mean(numeric_only=True))\n",
    "    else:\n",
    "        dfu = df.copy()\n",
    "        \n",
    "        \n",
    "    # Build query grid\n",
    "    xi = np.linspace(x_min, x_max, x_n)\n",
    "    yi = np.linspace(y_min, y_max, y_n)\n",
    "    X, Y = np.meshgrid(xi, yi, indexing=\"xy\")\n",
    "    grid_points = np.column_stack([X.ravel(), Y.ravel()])\n",
    "\n",
    "    # KDTree on unique points\n",
    "    pts = dfu[[\"x\", \"y\"]].to_numpy()\n",
    "    n_pts = len(pts)\n",
    "    if n_pts == 0:\n",
    "        raise ValueError(\"No input points to interpolate.\")\n",
    "        \n",
    "    k_eff = min(k, n_pts)  # in case dataset smaller than k\n",
    "    tree = KDTree(pts)\n",
    "    dist, ind = tree.query(grid_points, k=k_eff)\n",
    "\n",
    "    # Prepare variables to interpolate (numeric, excluding x,y)\n",
    "    all_numeric = dfu.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    variables = [c for c in all_numeric if c not in (\"x\", \"y\")]\n",
    "    if not variables:\n",
    "        raise ValueError(\"No numeric variables (besides x,y) found to interpolate.\")    \n",
    "        \n",
    "    # Compute weights (IDW or uniform if power==0)\n",
    "    if power == 0:\n",
    "        # uniform weights across k neighbors\n",
    "        weights = np.full_like(dist, 1.0 / dist.shape[1], dtype=float)\n",
    "    else:\n",
    "        # IDW weights; handle exact matches by setting that weight to 1\n",
    "        with np.errstate(divide='ignore'):\n",
    "            w = 1.0 / (np.power(dist, power) + 1e-12)\n",
    "        # If any distance is effectively zero for a row, make that neighbor carry full weight\n",
    "        zero_rows = np.any(dist < 1e-12, axis=1)\n",
    "        if np.any(zero_rows):\n",
    "            # For rows with zeros, zero all weights then set zeros to 1 (if multiple zeros, they’ll share equally)\n",
    "            w[zero_rows] = 0.0\n",
    "            zero_mask = dist[zero_rows] < 1e-12\n",
    "            # Normalize per-row among the zero-distance neighbors (could be >1 if duplicates landed exactly on grid)\n",
    "            w[zero_rows] = zero_mask / zero_mask.sum(axis=1, keepdims=True)\n",
    "        # Normalize remaining rows\n",
    "        row_sums = w.sum(axis=1, keepdims=True)\n",
    "        # Safeguard in case of any weird numerical issue\n",
    "        row_sums[row_sums == 0] = 1.0\n",
    "        weights = w / row_sums\n",
    "\n",
    "    # Interpolate each variable with the weights\n",
    "    out = {}\n",
    "    for var in variables:\n",
    "        print(f\"Interpolating {var} (k={k_eff}, power={power})\")\n",
    "        vals = dfu[var].to_numpy()\n",
    "        # Gather neighbor values for each grid point and apply weights\n",
    "        neigh_vals = vals[ind]                   # shape (n_grid, k_eff)\n",
    "        out[var] = np.sum(weights * neigh_vals, axis=1)\n",
    "\n",
    "    # Return flat DataFrame like your original (x,y alongside all variables)\n",
    "    out[\"x\"] = grid_points[:, 0]\n",
    "    out[\"y\"] = grid_points[:, 1]\n",
    "    interpolated_df = pd.DataFrame(out)\n",
    "\n",
    "    return interpolated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c48bf7-e12e-4162-b669-aab33f94f610",
   "metadata": {},
   "source": [
    "# test interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a9e8b-9a5f-4582-96bb-1491e485395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../resources/ttpv1/tsunami060s.csv\", comment='#', sep='\\s+')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a392cf-ba73-42a8-86f1-7dcfac2fb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_path = os.path.join(\"../resources/benchmark_templates/ttpv1.json\")\n",
    "with open(template_path, 'r') as f:\n",
    "    template = json.load(f)\n",
    "    for file_info in template['files']:\n",
    "        expected_structure = file_info\n",
    "        if \"grid\" in expected_structure:\n",
    "            interpolated_df = interpolate_data(df, expected_structure['grid'])\n",
    "interpolated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37746b93-94a6-4628-b488-598c87c6ba93",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ffc6e-cc46-451b-9f86-75037cc1cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bdfe6-47bf-4ccd-9fed-3c1dd2f26e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === inputs ===\n",
    "df = interpolated_df              # your regridded dataframe\n",
    "var = \"ssha\"                       # variable to plot\n",
    "variable_dict = {\"name\": var, \"unit\": \"m\"}  # tweak as needed\n",
    "\n",
    "# grid vectors\n",
    "x_unique = np.sort(df[\"x\"].unique())\n",
    "y_unique = np.sort(df[\"y\"].unique())\n",
    "nx, ny = len(x_unique), len(y_unique)\n",
    "\n",
    "# 2D field\n",
    "Z = df[var].to_numpy().reshape(ny, nx)\n",
    "\n",
    "# color limits (optional)\n",
    "zmin = float(np.nanmin(Z))\n",
    "zmax = float(np.nanmax(Z))\n",
    "\n",
    "# index of y closest to 0 (works even if 0 isn't exactly on grid)\n",
    "iy0 = int(np.argmin(np.abs(y_unique - 0.0)))\n",
    "y0 = y_unique[iy0]\n",
    "line_profile = Z[iy0, :]\n",
    "\n",
    "# figure with two columns: heatmap (left) + cross-section (right)\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    column_widths=[0.78, 0.22],\n",
    "    horizontal_spacing=0.06,\n",
    "    specs=[[{\"type\": \"heatmap\"}, {\"type\": \"xy\"}]],\n",
    "    subplot_titles=(\n",
    "        f\"Heatmap: {variable_dict['name']} [{variable_dict['unit']}]\",\n",
    "        f\"Cross-section at y={y0:.1f}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# heatmap (left)\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x=x_unique,\n",
    "        y=y_unique,\n",
    "        z=Z,\n",
    "        zmin=zmin, zmax=zmax,\n",
    "        colorscale=\"RdBu_r\",\n",
    "        colorbar=dict(title=f\"{variable_dict['name']} ({variable_dict['unit']})\")\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# draw y=0 (or closest) line on top of the heatmap\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=x_unique.min(), x1=x_unique.max(),\n",
    "    y0=y0, y1=y0,\n",
    "    line=dict(width=2, dash=\"dash\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# cross-section (right): value vs x at y≈0\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_unique,\n",
    "        y=line_profile,\n",
    "        mode=\"lines\",\n",
    "        name=f\"{variable_dict['name']} @ y={y0:.1f}\"\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# make the heatmap square: lock y to x scale on the left subplot\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1, row=1, col=1)\n",
    "\n",
    "# labels & layout\n",
    "fig.update_xaxes(title_text=\"x (m)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"y (m)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x (m)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=f\"{variable_dict['name']} ({variable_dict['unit']})\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    title=f\"Heatmap (200 km × 200 km) with cross-section at y=0\",\n",
    "    margin=dict(l=60, r=20, t=60, b=50),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c6357-a84b-4e58-989e-4dc289ec2fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:plotly_env]",
   "language": "python",
   "name": "conda-env-plotly_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
