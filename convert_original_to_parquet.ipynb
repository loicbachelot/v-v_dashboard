{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f2331fa-6a64-4dd1-92d7-58e9444f8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e0aeb25-f036-451e-b94b-2655efc9a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds_to_time(seconds):\n",
    "    years = seconds / (365.25 * 24 * 3600)\n",
    "    days = (seconds / (24 * 3600))\n",
    "    hours = seconds / 3600\n",
    "    seconds = seconds\n",
    "    return years, days, hours, seconds\n",
    "\n",
    "def extract_header(input_path):\n",
    "    \"\"\"Extract and parse the common header from a .dat file.\"\"\"\n",
    "    header_data = {}\n",
    "    with open(input_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"# File:\"):  # Skip file-specific lines\n",
    "                continue\n",
    "            if line.startswith('#'):\n",
    "                # Extract key-value pairs, if present\n",
    "                if '=' in line:\n",
    "                    key, value = line[2:].strip().split('=', 1)\n",
    "                    header_data[key.strip()] = value.strip()\n",
    "                else:\n",
    "                    # Store plain comments\n",
    "                    header_data.setdefault('comments', []).append(line[2:].strip())\n",
    "    return header_data\n",
    "\n",
    "def process_files(input_folder, code_name, version):\n",
    "    # Create the output folder based on the code name and version\n",
    "    output_folder = f\"./parquet_examples/{code_name}_v{version}/\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    file_list = []  # Store filenames for the metadata summary\n",
    "    common_header = None  # Store the shared header\n",
    "\n",
    "    # Loop through all .dat files in the input folder and subdirectories\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dat\"):\n",
    "                input_path = os.path.join(root, file)\n",
    "                depth = file.split('dp')[-1].split('.')[0]  # Extract depth from filename\n",
    "                output_path = os.path.join(output_folder, f\"{code_name}_v{version}_{depth}.parquet\")\n",
    "\n",
    "                try:\n",
    "                    # Extract the common header only from the first file\n",
    "                    if common_header is None:\n",
    "                        common_header = extract_header(input_path)\n",
    "\n",
    "                    # Collect the filename for the metadata summary\n",
    "                    file_list.append(file)\n",
    "\n",
    "                    # Read the .dat file into a DataFrame\n",
    "                    df = pd.read_csv(input_path, comment='#', delim_whitespace=True)\n",
    "                    df['years'], df['days'], df['hours'], df['seconds'] = convert_seconds_to_time(df['t'])\n",
    "\n",
    "                    # Save to Parquet\n",
    "                    df.to_parquet(output_path, index=False)\n",
    "                    print(f\"Saved: {output_path}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {input_path}: {e}\")\n",
    "\n",
    "    # Prepare the metadata as a dictionary\n",
    "    metadata = {\n",
    "        \"common_header\": common_header,\n",
    "        \"processed_files\": file_list\n",
    "    }\n",
    "\n",
    "    # Write the metadata to a JSON file\n",
    "    metadata_path = os.path.join(output_folder, \"metadata.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"Metadata saved: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25f31873-77f9-4cf8-9f0d-8d5e4c1f3c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_000.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_025.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_050.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_075.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_100.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_125.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_150.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_175.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_200.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_250.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_300.parquet\n",
      "Saved: ./parquet_examples/thrase_v1/thrase_v1_350.parquet\n",
      "Metadata saved: ./parquet_examples/thrase_v1/metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_folder = \"./resources/bp1-qd/erickson/\"\n",
    "code_name = \"thrase\"\n",
    "version = \"1\"\n",
    "process_files(input_folder, code_name, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "843cbdff-e1d2-4a8a-86e7-39eca91f7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds_to_time(seconds):\n",
    "    years = seconds / (365.25 * 24 * 3600)\n",
    "    days = (seconds / (24 * 3600))\n",
    "    hours = seconds / 3600\n",
    "    seconds = seconds\n",
    "    return years, days, hours, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe226abc-62a6-4f25-9d15-9a8bbb685bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp000.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp000.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp025.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp025.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp050.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp050.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp075.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp075.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp100.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp100.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp125.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp125.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp150.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp150.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp175.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp175.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp200.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp200.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp250.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp250.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp300.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp300.parquet\n",
      "Processing: ./resources/bp1-qd/erickson\\erickson_bp1-qd_fltst_dp350.dat\n",
      "Saved: ./parquet_examples/erickson_bp1-qd_fltst_dp350.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp000.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp000.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp025.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp025.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp050.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp050.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp075.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp075.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp100.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp100.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp125.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp125.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp150.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp150.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp175.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp175.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp200.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp200.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp250.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp250.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp300.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp300.parquet\n",
      "Processing: ./resources/bp1-qd/jiang\\jiang_bp1-qd_fltst_dp350.dat\n",
      "Saved: ./parquet_examples/jiang_bp1-qd_fltst_dp350.parquet\n"
     ]
    }
   ],
   "source": [
    "# Input and output folders\n",
    "input_folder = \"./resources/bp1-qd/erickson/\"\n",
    "output_folder = \"./parquet_examples/\"\n",
    "code_name = \"thrase\"\n",
    "version = \"1\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through all files in the input folder and subdirectories\n",
    "for root, _, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".dat\"):\n",
    "            # Construct full input and output file paths\n",
    "            input_path = os.path.join(root, file)\n",
    "            output_file = file.replace(\".dat\", \".parquet\")\n",
    "            output_path = os.path.join(output_folder, output_file)\n",
    "\n",
    "            try:\n",
    "                # Read the .dat file and convert to Parquet\n",
    "                print(f\"Processing: {input_path}\")\n",
    "                df = pd.read_csv(input_path, comment='#', delim_whitespace=True)\n",
    "                df['years'], df['days'], df['hours'], df['seconds'] = convert_seconds_to_time(df['t'])\n",
    "                df.to_parquet(output_path, index=False)\n",
    "                print(f\"Saved: {output_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {input_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0991362-8fb1-465c-83ae-8117cd8b817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 11.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>slip</th>\n",
       "      <th>slip_rate</th>\n",
       "      <th>shear_stress</th>\n",
       "      <th>state</th>\n",
       "      <th>years</th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>seconds</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>26.546122</td>\n",
       "      <td>0.591409</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>9.999999e-13</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>26.546122</td>\n",
       "      <td>3.903090</td>\n",
       "      <td>3.168809e-11</td>\n",
       "      <td>1.157407e-08</td>\n",
       "      <td>2.777778e-07</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.099213e+04</td>\n",
       "      <td>5.618357e-06</td>\n",
       "      <td>-9.562926</td>\n",
       "      <td>26.546126</td>\n",
       "      <td>4.278376</td>\n",
       "      <td>3.483197e-04</td>\n",
       "      <td>1.272238e-01</td>\n",
       "      <td>3.053370e+00</td>\n",
       "      <td>1.099213e+04</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.113129e+06</td>\n",
       "      <td>1.530747e-05</td>\n",
       "      <td>-13.065780</td>\n",
       "      <td>26.548487</td>\n",
       "      <td>6.614980</td>\n",
       "      <td>1.303372e-01</td>\n",
       "      <td>4.760566e+01</td>\n",
       "      <td>1.142536e+03</td>\n",
       "      <td>4.113129e+06</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.437484e+07</td>\n",
       "      <td>1.572737e-05</td>\n",
       "      <td>-14.214194</td>\n",
       "      <td>26.559678</td>\n",
       "      <td>7.387069</td>\n",
       "      <td>7.723920e-01</td>\n",
       "      <td>2.821162e+02</td>\n",
       "      <td>6.770788e+03</td>\n",
       "      <td>2.437484e+07</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43938</th>\n",
       "      <td>9.466306e+10</td>\n",
       "      <td>8.945083e+01</td>\n",
       "      <td>-15.166594</td>\n",
       "      <td>28.542657</td>\n",
       "      <td>9.170264</td>\n",
       "      <td>2.999691e+03</td>\n",
       "      <td>1.095637e+06</td>\n",
       "      <td>2.629529e+07</td>\n",
       "      <td>9.466306e+10</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43939</th>\n",
       "      <td>9.466306e+10</td>\n",
       "      <td>8.945083e+01</td>\n",
       "      <td>-15.166594</td>\n",
       "      <td>28.542657</td>\n",
       "      <td>9.170264</td>\n",
       "      <td>2.999691e+03</td>\n",
       "      <td>1.095637e+06</td>\n",
       "      <td>2.629529e+07</td>\n",
       "      <td>9.466306e+10</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43940</th>\n",
       "      <td>9.466307e+10</td>\n",
       "      <td>8.945083e+01</td>\n",
       "      <td>-15.166594</td>\n",
       "      <td>28.542663</td>\n",
       "      <td>9.170268</td>\n",
       "      <td>2.999692e+03</td>\n",
       "      <td>1.095637e+06</td>\n",
       "      <td>2.629530e+07</td>\n",
       "      <td>9.466307e+10</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43941</th>\n",
       "      <td>9.466954e+10</td>\n",
       "      <td>8.945083e+01</td>\n",
       "      <td>-15.166752</td>\n",
       "      <td>28.545752</td>\n",
       "      <td>9.172162</td>\n",
       "      <td>2.999897e+03</td>\n",
       "      <td>1.095712e+06</td>\n",
       "      <td>2.629709e+07</td>\n",
       "      <td>9.466954e+10</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43942</th>\n",
       "      <td>9.467078e+10</td>\n",
       "      <td>8.945083e+01</td>\n",
       "      <td>-15.166780</td>\n",
       "      <td>28.546343</td>\n",
       "      <td>9.172524</td>\n",
       "      <td>2.999936e+03</td>\n",
       "      <td>1.095727e+06</td>\n",
       "      <td>2.629744e+07</td>\n",
       "      <td>9.467078e+10</td>\n",
       "      <td>erickson_dp000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43943 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t          slip  slip_rate  shear_stress     state  \\\n",
       "0      0.000000e+00  0.000000e+00  -9.000000     26.546122  0.591409   \n",
       "1      1.000000e-03  9.999999e-13  -9.000000     26.546122  3.903090   \n",
       "2      1.099213e+04  5.618357e-06  -9.562926     26.546126  4.278376   \n",
       "3      4.113129e+06  1.530747e-05 -13.065780     26.548487  6.614980   \n",
       "4      2.437484e+07  1.572737e-05 -14.214194     26.559678  7.387069   \n",
       "...             ...           ...        ...           ...       ...   \n",
       "43938  9.466306e+10  8.945083e+01 -15.166594     28.542657  9.170264   \n",
       "43939  9.466306e+10  8.945083e+01 -15.166594     28.542657  9.170264   \n",
       "43940  9.466307e+10  8.945083e+01 -15.166594     28.542663  9.170268   \n",
       "43941  9.466954e+10  8.945083e+01 -15.166752     28.545752  9.172162   \n",
       "43942  9.467078e+10  8.945083e+01 -15.166780     28.546343  9.172524   \n",
       "\n",
       "              years          days         hours       seconds    dataset_name  \n",
       "0      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  erickson_dp000  \n",
       "1      3.168809e-11  1.157407e-08  2.777778e-07  1.000000e-03  erickson_dp000  \n",
       "2      3.483197e-04  1.272238e-01  3.053370e+00  1.099213e+04  erickson_dp000  \n",
       "3      1.303372e-01  4.760566e+01  1.142536e+03  4.113129e+06  erickson_dp000  \n",
       "4      7.723920e-01  2.821162e+02  6.770788e+03  2.437484e+07  erickson_dp000  \n",
       "...             ...           ...           ...           ...             ...  \n",
       "43938  2.999691e+03  1.095637e+06  2.629529e+07  9.466306e+10  erickson_dp000  \n",
       "43939  2.999691e+03  1.095637e+06  2.629529e+07  9.466306e+10  erickson_dp000  \n",
       "43940  2.999692e+03  1.095637e+06  2.629530e+07  9.466307e+10  erickson_dp000  \n",
       "43941  2.999897e+03  1.095712e+06  2.629709e+07  9.466954e+10  erickson_dp000  \n",
       "43942  2.999936e+03  1.095727e+06  2.629744e+07  9.467078e+10  erickson_dp000  \n",
       "\n",
       "[43943 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ds = pd.read_parquet(\"./parquet_examples/erickson_bp1-qd_fltst_dp000.parquet\")\n",
    "ds['dataset_name'] = f\"erickson_dp000\"\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaaaa84f-ca06-4aa5-8c16-70d2d9dc4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = ['erickson', 'jiang']\n",
    "depth = '025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afbccef3-02ed-4e16-87f7-b8df253d2d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['erickson_dp025', 'jiang_dp025']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names = [name + '_dp' + depth for name in dataset_list]\n",
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b57df781-f619-4084-b789-adc1bd9ba113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>slip</th>\n",
       "      <th>slip_rate</th>\n",
       "      <th>shear_stress</th>\n",
       "      <th>state</th>\n",
       "      <th>years</th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>seconds</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [t, slip, slip_rate, shear_stress, state, years, days, hours, seconds, dataset_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = ds[ds['dataset_name'].isin(dataset_names)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c13f579-aeff-4344-b03b-cf643ccb0e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['erickson', 'jiang']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset_names = [name.split('_')[0] for name in dataset_names if name not in ds['dataset_name'].values]\n",
    "filtered_dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72952d69-e8ec-4253-870d-3ea1083548da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GNN_torch]",
   "language": "python",
   "name": "conda-env-GNN_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
